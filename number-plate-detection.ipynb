{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-12T15:15:40.879522Z","iopub.status.busy":"2024-07-12T15:15:40.878868Z","iopub.status.idle":"2024-07-12T15:15:42.087825Z","shell.execute_reply":"2024-07-12T15:15:42.086469Z","shell.execute_reply.started":"2024-07-12T15:15:40.879491Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         pass\n","#         print(os.path.join(dirname, filename))\n","#\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T15:24:59.209264Z","iopub.status.busy":"2024-07-12T15:24:59.208819Z","iopub.status.idle":"2024-07-12T15:24:59.411394Z","shell.execute_reply":"2024-07-12T15:24:59.410602Z","shell.execute_reply.started":"2024-07-12T15:24:59.209230Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","import shutil\n","from bs4 import BeautifulSoup\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T15:26:14.699415Z","iopub.status.busy":"2024-07-12T15:26:14.698491Z","iopub.status.idle":"2024-07-12T15:26:14.712299Z","shell.execute_reply":"2024-07-12T15:26:14.711421Z","shell.execute_reply.started":"2024-07-12T15:26:14.699380Z"},"trusted":true},"outputs":[],"source":["def normalized_coordinates(filename, width, height, xmin, ymin, xmax, ymax):\n","    \"\"\"Take in image coordinates (unnormalized) as input, return normalized values \n","    \"\"\"\n","    \n","    xmin, xmax = xmin / width, xmax / width\n","    ymin, ymax = ymin / height, ymax/ height\n","\n","    width = xmax-xmin\n","    height = ymax-ymin\n","    x_center = xmin + (width / 2)\n","    y_center = ymin + (height / 2)\n","\n","    return x_center, y_center, width, height\n","\n","def write_label(filename, x_center, y_center, width, height):\n","    \"\"\"Save image's coordinates in text file named \"filename\"\n","    \"\"\"\n","    with open(filename, mode='w') as outf:\n","        outf.write(f\"{0} {x_center} {y_center} {width} {height}\\n\")\n","        \n","def parse_xml_tags(data):\n","    \"\"\"Parse xml label file, return image file name, and its coordinates as a dictionary\n","    \"\"\"\n","    tags = ['filename', 'width', 'height', 'xmin', 'ymin', 'xmax', 'ymax']\n","    Bs_data = BeautifulSoup(data, \"lxml\")\n","    d = dict()\n","\n","    for t in tags:\n","        text = Bs_data.find(t).text\n","        if all(c.isdigit() for c in text):\n","            d[t] = int(text)\n","        else:\n","            d[t] = text\n","    return d\n","\n","def build_data(dir_folder, ann_file_list, img_dir):\n","    \"\"\"Write xml labels to text file with specifications format, save at 'labels' folder.\n","        Move image to 'images' folder\n","    \"\"\"\n","    images_folder = f\"{dir_folder}/images\"\n","    labels_folder = f\"{dir_folder}/labels\"\n","    \n","    os.makedirs(images_folder, exist_ok = True)\n","    os.makedirs(labels_folder, exist_ok = True)\n","\n","\n","    for ann_file in ann_file_list:\n","        with open(ann_file, 'r') as f:\n","            label = parse_xml_tags(f.read())\n","         \n","        img_file_name = label['filename']\n","        x_center, y_center, width, height = normalized_coordinates(**label)\n","         \n","        # save at 'labels' folder\n","        write_label(f\"{labels_folder}/{img_file_name.split('.')[0]}.txt\", x_center, y_center, width, height)\n","         \n","         # Move image to 'images' folder\n","        shutil.copy(f\"{img_dir}/{img_file_name}\", f\"{images_folder}/{img_file_name}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T15:26:49.105180Z","iopub.status.busy":"2024-07-12T15:26:49.104175Z","iopub.status.idle":"2024-07-12T15:26:52.648408Z","shell.execute_reply":"2024-07-12T15:26:52.647548Z","shell.execute_reply.started":"2024-07-12T15:26:49.105142Z"},"trusted":true},"outputs":[],"source":["import glob\n","\n","dir_folder = \"plate_datasets\"\n","\n","ann_list = glob.glob('images/*.xml')\n","build_data(\"ultralytics/cfg/datasets/\" + dir_folder, ann_list, \"images\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T15:27:34.498881Z","iopub.status.busy":"2024-07-12T15:27:34.498478Z","iopub.status.idle":"2024-07-12T15:27:34.527855Z","shell.execute_reply":"2024-07-12T15:27:34.526933Z","shell.execute_reply.started":"2024-07-12T15:27:34.498851Z"},"trusted":true},"outputs":[],"source":["import yaml\n","\n","data = {\n","    \"path\": dir_folder,\n","    \"train\": \"images\",\n","    \"val\": \"images\",\n","    \"names\": {0: \"car_lisence_plate\"}\n","    }\n","\n","with open('dataset.yaml', 'w') as outfile:\n","    yaml.dump(data, outfile, default_flow_style=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-12T15:27:41.620460Z","iopub.status.busy":"2024-07-12T15:27:41.619682Z","iopub.status.idle":"2024-07-12T15:27:41.626949Z","shell.execute_reply":"2024-07-12T15:27:41.625946Z","shell.execute_reply.started":"2024-07-12T15:27:41.620425Z"},"trusted":true},"outputs":[],"source":["assert len(os.listdir(\"./ultralytics/cfg/datasets/plate_datasets/labels\")) == len(os.listdir(\"ultralytics/cfg/datasets/plate_datasets/images\"))"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"DLL load failed while importing _C: The specified module could not be found.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n","File \u001b[1;32md:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\ultralytics\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Set ENV Variables (place before imports)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# reduce CPU utilization during training\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explorer\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n","File \u001b[1;32md:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\ultralytics\\data\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO ðŸš€, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dataloader, build_grounding, build_yolo_dataset, load_inference_source\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     ClassificationDataset,\n\u001b[0;32m      7\u001b[0m     GroundingDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     YOLOMultiModalDataset,\n\u001b[0;32m     12\u001b[0m )\n","File \u001b[1;32md:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\ultralytics\\data\\base.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM\n","File \u001b[1;32md:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\torch\\utils\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_osp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthroughput_benchmark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThroughputBenchmark\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpp_backtrace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cpp_backtrace\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rename_privateuse1_backend, generate_methods_for_privateuse1_backend\n","File \u001b[1;32md:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\torch\\utils\\throughput_benchmark.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_time\u001b[39m(time_us\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, time_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, time_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Define time formatting.\"\"\"\u001b[39;00m\n","\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _C: The specified module could not be found."]}],"source":["from ultralytics import YOLO"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(file, map_location=\"cpu\")\n"]}],"source":["model = YOLO(\"yolov8n.pt\" )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.2.55  Python-3.11.9 torch-2.4.0+cu124 CUDA:0 (NVIDIA GeForce GTX 1050, 4096MiB)\n","\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=dataset.yaml, epochs=30, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=runs, name=exp, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\exp\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(file, map_location=\"cpu\")\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks skipped . Unable to load YOLOv8n due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:267: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Vegeta\\Projects\\DL projects\\Number plate detection\\ultralytics\\cfg\\datasets\\plate_datasets\\labels.cache... 225 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<?, ?it/s]\n"]}],"source":["results = model.train(data='dataset.yaml', epochs=30, batch=32, imgsz=640,  project='runs', name='exp',  exist_ok=True, device='cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/1 d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.jpeg: 544x640 1 car_lisence_plate, 295.6ms\n","Speed: 13.8ms preprocess, 295.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n"]},{"data":{"text/plain":["1"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["results= model(\"TEST\\TEST.jpeg\")\n","len(results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results[0].show()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\env\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(file, map_location=\"cpu\")\n"]}],"source":["from ultralytics import YOLO\n","best_model = YOLO(\"best1.pt\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/1 d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.jpeg: 544x640 1 car_lisence_plate, 4054.9ms\n","Speed: 176.2ms preprocess, 4054.9ms inference, 145.6ms postprocess per image at shape (1, 3, 544, 640)\n"]}],"source":["results= best_model(\"TEST\\TEST.jpeg\")\n","results[0].show()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["results= best_model(\"TEST\\TEST.mp4\", stream=True, conf=0.02, iou=0.7)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","video 1/1 (frame 1/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 1 car_lisence_plate, 1520.1ms\n","video 1/1 (frame 2/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1517.0ms\n","video 1/1 (frame 3/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1672.3ms\n","video 1/1 (frame 4/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1488.5ms\n","video 1/1 (frame 5/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1214.2ms\n","video 1/1 (frame 6/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1649.5ms\n","video 1/1 (frame 7/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1773.0ms\n","video 1/1 (frame 8/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1421.4ms\n","video 1/1 (frame 9/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1634.5ms\n","video 1/1 (frame 10/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1678.7ms\n","video 1/1 (frame 11/10075) d:\\Vegeta\\Projects\\DL projects\\Number plate detection\\TEST\\TEST.mp4: 384x640 (no detections), 1502.1ms\n"]}],"source":["for i,result in enumerate(results):\n","    if i == 10:\n","        break\n","    if len(result) > 0:\n","        result.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2224491,"sourceId":3753395,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
